# ğŸ§  MindMate â€“ AI-Powered Mental Health Chatbot

**MindMate** is an AI-driven mental health chatbot built with LangChain, ChromaDB, and a local LLM (via Ollama). It uses Retrieval-Augmented Generation (RAG) to provide context-aware, supportive responses to users dealing with mental health concerns. All responses are powered by a custom-trained mental health dataset, ensuring empathy and relevance in every interaction.

---

## ğŸŒŸ Features

- ğŸ’¬ **Conversational Mental Health Support**
- ğŸ” **RAG Pipeline** using LangChain + Chroma for smart context-aware responses
- ğŸ§  **Local LLM** integration using `phi3:3.8b` via Ollama
- ğŸ§¾ **Custom Dataset**: Based on `ShenLab/MentalChat16K` for high-quality Q&A
- ğŸ“¦ **Modular Codebase**: Organized structure for easy updates and scaling
- ğŸ³ **Docker-ready** for local development and deployment
- ğŸ§ª **Streamlit Interface** for user-friendly interaction

---

## ğŸ› ï¸ Tech Stack

| Layer      | Tools Used                                |
|------------|--------------------------------------------|
| Backend    | Python, LangChain, Ollama (phi3)           |
| Embeddings | HuggingFace Sentence Transformers          |
| Vector DB  | Chroma                                     |
| UI         | Streamlit                                  |
| Deployment | Docker                                     |
| Dataset    | ShenLab/MentalChat16K                      |

---

## ğŸ“ Project Structure

```bash
mindmate/
â”œâ”€â”€ llama.py             # Connects to local LLM using Ollama
â”œâ”€â”€ vectorstore.py       # Loads, chunks & vectorizes documents
â”œâ”€â”€ ragpipeline.py       # Combines retriever with LLM using LangChain
â”œâ”€â”€ data.ipynb           # Dataset inspection and experimentation
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .venv/               # Virtual environment
â””â”€â”€ README.md            # Project overview
```

---

## âš™ï¸ How It Works

1. **Load Dataset**
   - Imports Q&A pairs from `ShenLab/MentalChat16K`
   - Preprocesses and chunks text into ~500-character sections

2. **Embed & Store**
   - Uses HuggingFace Transformers to embed text chunks
   - Stores vectors in ChromaDB for efficient similarity-based retrieval

3. **Retrieve + Generate**
   - Accepts user questions via the Streamlit UI
   - Retrieves top relevant chunks from ChromaDB
   - Combines context with the user's query and sends it to the local `phi3` LLM (via Ollama) using LangChain

---

## ğŸš€ Getting Started

### ğŸ§± Prerequisites

- Python 3.9+
- [Ollama](https://ollama.com/) installed and running with `phi3:3.8b` model
- Docker (optional, for containerized deployment)

---

### ğŸ”§ Installation & Running the Project

#### âœ… Step 1: Clone the Repository

```bash
git clone https://github.com/krish-kavya-02/mental-health-chatbot.git
cd mental-health-chatbot
```

#### âœ… Step 2: Set Up Python Virtual Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# On Windows
.venv\Scripts\activate

# On macOS/Linux
source .venv/bin/activate
```

#### âœ… Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ§ª Run the Chatbot Locally

Make sure the phi3:3.8b model is downloaded and running using Ollama:

```bash
ollama run phi3:3.8b
```

Then in another terminal, run:

```bash
python vectorstore.py
```

```bash
python ragpipeline.py
```

```bash
streamlit run llama.py
```

Visit http://localhost:8501 in your browser to start chatting with MindMate ğŸ§ .

---


## ğŸ‘¨â€ğŸ’» Author

**Krish Kavya Upadhyay**

- ğŸŒ [GitHub](https://github.com/krish-kavya-02)
- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/krish-kavya-upadhyay-8b3322355/)
